{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We spend a lot of money on education every year! In general, we believe that the more we spend, the better our schools are and the better our students perform. But do we really know that?\n",
    "\n",
    "To adress these questions, we will spend today looking at a US education dataset and see what we can learn about indicators of student performance. In particular, we want to answer the question: what are useful indicators to predict student performance on national exams?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Poking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by importing our data and seeing what we've got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress Pandas SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/states_edu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1715, 25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given that this dataset describes \"K-12 financial, enrollment, and achievement data in one place\". Each row is one state in one year, and includes variables for revenue categories, expenditure types, enrollment numbers, and exam scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885.0</td>\n",
       "      <td>304177.0</td>\n",
       "      <td>1659028.0</td>\n",
       "      <td>715680.0</td>\n",
       "      <td>2653798.0</td>\n",
       "      <td>1481703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57948.0</td>\n",
       "      <td>58025.0</td>\n",
       "      <td>41167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>731634.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591.0</td>\n",
       "      <td>106780.0</td>\n",
       "      <td>720711.0</td>\n",
       "      <td>222100.0</td>\n",
       "      <td>972488.0</td>\n",
       "      <td>498362.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9748.0</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>6714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122487.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079.0</td>\n",
       "      <td>297888.0</td>\n",
       "      <td>1369815.0</td>\n",
       "      <td>1590376.0</td>\n",
       "      <td>3401580.0</td>\n",
       "      <td>1435908.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55433.0</td>\n",
       "      <td>49081.0</td>\n",
       "      <td>37410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>673477.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959.0</td>\n",
       "      <td>178571.0</td>\n",
       "      <td>958785.0</td>\n",
       "      <td>574603.0</td>\n",
       "      <td>1743022.0</td>\n",
       "      <td>964323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34632.0</td>\n",
       "      <td>36011.0</td>\n",
       "      <td>27651.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441490.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025.0</td>\n",
       "      <td>2072470.0</td>\n",
       "      <td>16546514.0</td>\n",
       "      <td>7641041.0</td>\n",
       "      <td>27138832.0</td>\n",
       "      <td>14358922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>418418.0</td>\n",
       "      <td>363296.0</td>\n",
       "      <td>270675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5254844.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992     NaN      2678885.0         304177.0   \n",
       "1      1992_ALASKA      ALASKA  1992     NaN      1049591.0         106780.0   \n",
       "2     1992_ARIZONA     ARIZONA  1992     NaN      3258079.0         297888.0   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992     NaN      1711959.0         178571.0   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992     NaN     26260025.0        2072470.0   \n",
       "\n",
       "   STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "0      1659028.0       715680.0          2653798.0                1481703.0   \n",
       "1       720711.0       222100.0           972488.0                 498362.0   \n",
       "2      1369815.0      1590376.0          3401580.0                1435908.0   \n",
       "3       958785.0       574603.0          1743022.0                 964323.0   \n",
       "4     16546514.0      7641041.0         27138832.0               14358922.0   \n",
       "\n",
       "   ...  GRADES_4_G  GRADES_8_G  GRADES_12_G  GRADES_1_8_G  GRADES_9_12_G  \\\n",
       "0  ...     57948.0     58025.0      41167.0           NaN            NaN   \n",
       "1  ...      9748.0      8789.0       6714.0           NaN            NaN   \n",
       "2  ...     55433.0     49081.0      37410.0           NaN            NaN   \n",
       "3  ...     34632.0     36011.0      27651.0           NaN            NaN   \n",
       "4  ...    418418.0    363296.0     270675.0           NaN            NaN   \n",
       "\n",
       "   GRADES_ALL_G  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  AVG_READING_4_SCORE  \\\n",
       "0      731634.0             208.0             252.0                207.0   \n",
       "1      122487.0               NaN               NaN                  NaN   \n",
       "2      673477.0             215.0             265.0                209.0   \n",
       "3      441490.0             210.0             256.0                211.0   \n",
       "4     5254844.0             208.0             261.0                202.0   \n",
       "\n",
       "   AVG_READING_8_SCORE  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PRIMARY_KEY', 'STATE', 'YEAR', 'ENROLL', 'TOTAL_REVENUE',\n",
       "       'FEDERAL_REVENUE', 'STATE_REVENUE', 'LOCAL_REVENUE',\n",
       "       'TOTAL_EXPENDITURE', 'INSTRUCTION_EXPENDITURE',\n",
       "       'SUPPORT_SERVICES_EXPENDITURE', 'OTHER_EXPENDITURE',\n",
       "       'CAPITAL_OUTLAY_EXPENDITURE', 'GRADES_PK_G', 'GRADES_KG_G',\n",
       "       'GRADES_4_G', 'GRADES_8_G', 'GRADES_12_G', 'GRADES_1_8_G',\n",
       "       'GRADES_9_12_G', 'GRADES_ALL_G', 'AVG_MATH_4_SCORE', 'AVG_MATH_8_SCORE',\n",
       "       'AVG_READING_4_SCORE', 'AVG_READING_8_SCORE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's rename our columns to make them more intuitive\n",
    "df.rename({\n",
    "    'GRADES_PK_G':'ENROLL_PREK',\n",
    "    'GRADES_KG_G':'ENROLL_KINDER',\n",
    "    'GRADES_4_G':'ENROLL_4',\n",
    "    'GRADES_8_G':'ENROLL_8',\n",
    "    'GRADES_12_G':'ENROLL_12',\n",
    "    'GRADES_1_8_G':'ENROLL_PRIMARY',\n",
    "    'GRADES_9_12_G':'ENROLL_HS',\n",
    "    'GRADES_ALL_G':'ENROLL_ALL',\n",
    "    'ENROLL':'ENROLL_ALL_EST'\n",
    "    },\n",
    "    axis=1,inplace=True)\n",
    "#inplace return copy of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL_ALL_EST</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ENROLL_4</th>\n",
       "      <th>ENROLL_8</th>\n",
       "      <th>ENROLL_12</th>\n",
       "      <th>ENROLL_PRIMARY</th>\n",
       "      <th>ENROLL_HS</th>\n",
       "      <th>ENROLL_ALL</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885.0</td>\n",
       "      <td>304177.0</td>\n",
       "      <td>1659028.0</td>\n",
       "      <td>715680.0</td>\n",
       "      <td>2653798.0</td>\n",
       "      <td>1481703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57948.0</td>\n",
       "      <td>58025.0</td>\n",
       "      <td>41167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>731634.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591.0</td>\n",
       "      <td>106780.0</td>\n",
       "      <td>720711.0</td>\n",
       "      <td>222100.0</td>\n",
       "      <td>972488.0</td>\n",
       "      <td>498362.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9748.0</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>6714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122487.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079.0</td>\n",
       "      <td>297888.0</td>\n",
       "      <td>1369815.0</td>\n",
       "      <td>1590376.0</td>\n",
       "      <td>3401580.0</td>\n",
       "      <td>1435908.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55433.0</td>\n",
       "      <td>49081.0</td>\n",
       "      <td>37410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>673477.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959.0</td>\n",
       "      <td>178571.0</td>\n",
       "      <td>958785.0</td>\n",
       "      <td>574603.0</td>\n",
       "      <td>1743022.0</td>\n",
       "      <td>964323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34632.0</td>\n",
       "      <td>36011.0</td>\n",
       "      <td>27651.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441490.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025.0</td>\n",
       "      <td>2072470.0</td>\n",
       "      <td>16546514.0</td>\n",
       "      <td>7641041.0</td>\n",
       "      <td>27138832.0</td>\n",
       "      <td>14358922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>418418.0</td>\n",
       "      <td>363296.0</td>\n",
       "      <td>270675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5254844.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL_ALL_EST  TOTAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992             NaN      2678885.0   \n",
       "1      1992_ALASKA      ALASKA  1992             NaN      1049591.0   \n",
       "2     1992_ARIZONA     ARIZONA  1992             NaN      3258079.0   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992             NaN      1711959.0   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992             NaN     26260025.0   \n",
       "\n",
       "   FEDERAL_REVENUE  STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  \\\n",
       "0         304177.0      1659028.0       715680.0          2653798.0   \n",
       "1         106780.0       720711.0       222100.0           972488.0   \n",
       "2         297888.0      1369815.0      1590376.0          3401580.0   \n",
       "3         178571.0       958785.0       574603.0          1743022.0   \n",
       "4        2072470.0     16546514.0      7641041.0         27138832.0   \n",
       "\n",
       "   INSTRUCTION_EXPENDITURE  ...  ENROLL_4  ENROLL_8  ENROLL_12  \\\n",
       "0                1481703.0  ...   57948.0   58025.0    41167.0   \n",
       "1                 498362.0  ...    9748.0    8789.0     6714.0   \n",
       "2                1435908.0  ...   55433.0   49081.0    37410.0   \n",
       "3                 964323.0  ...   34632.0   36011.0    27651.0   \n",
       "4               14358922.0  ...  418418.0  363296.0   270675.0   \n",
       "\n",
       "   ENROLL_PRIMARY  ENROLL_HS  ENROLL_ALL  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  \\\n",
       "0             NaN        NaN    731634.0             208.0             252.0   \n",
       "1             NaN        NaN    122487.0               NaN               NaN   \n",
       "2             NaN        NaN    673477.0             215.0             265.0   \n",
       "3             NaN        NaN    441490.0             210.0             256.0   \n",
       "4             NaN        NaN   5254844.0             208.0             261.0   \n",
       "\n",
       "   AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n",
       "0                207.0                  NaN  \n",
       "1                  NaN                  NaN  \n",
       "2                209.0                  NaN  \n",
       "3                211.0                  NaN  \n",
       "4                202.0                  NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking closer at the data, there are a lot of 'NaN' values... what are those?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a numpy value which represents missnig or invalid data (not-a-number)\n",
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it is treated as a float, so it is easily compatible with numpy and pandas\n",
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily find and describe missing values with `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                        0\n",
       "STATE                              0\n",
       "YEAR                               0\n",
       "ENROLL_ALL_EST                   491\n",
       "TOTAL_REVENUE                    440\n",
       "FEDERAL_REVENUE                  440\n",
       "STATE_REVENUE                    440\n",
       "LOCAL_REVENUE                    440\n",
       "TOTAL_EXPENDITURE                440\n",
       "INSTRUCTION_EXPENDITURE          440\n",
       "SUPPORT_SERVICES_EXPENDITURE     440\n",
       "OTHER_EXPENDITURE                491\n",
       "CAPITAL_OUTLAY_EXPENDITURE       440\n",
       "ENROLL_PREK                      173\n",
       "ENROLL_KINDER                     83\n",
       "ENROLL_4                          83\n",
       "ENROLL_8                          83\n",
       "ENROLL_12                         83\n",
       "ENROLL_PRIMARY                   695\n",
       "ENROLL_HS                        644\n",
       "ENROLL_ALL                        83\n",
       "AVG_MATH_4_SCORE                1150\n",
       "AVG_MATH_8_SCORE                1113\n",
       "AVG_READING_4_SCORE             1065\n",
       "AVG_READING_8_SCORE             1153\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will print the number of missing values in each column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                     1715\n",
       "STATE                           1715\n",
       "YEAR                            1715\n",
       "ENROLL_ALL_EST                  1224\n",
       "TOTAL_REVENUE                   1275\n",
       "FEDERAL_REVENUE                 1275\n",
       "STATE_REVENUE                   1275\n",
       "LOCAL_REVENUE                   1275\n",
       "TOTAL_EXPENDITURE               1275\n",
       "INSTRUCTION_EXPENDITURE         1275\n",
       "SUPPORT_SERVICES_EXPENDITURE    1275\n",
       "OTHER_EXPENDITURE               1224\n",
       "CAPITAL_OUTLAY_EXPENDITURE      1275\n",
       "ENROLL_PREK                     1542\n",
       "ENROLL_KINDER                   1632\n",
       "ENROLL_4                        1632\n",
       "ENROLL_8                        1632\n",
       "ENROLL_12                       1632\n",
       "ENROLL_PRIMARY                  1020\n",
       "ENROLL_HS                       1071\n",
       "ENROLL_ALL                      1632\n",
       "AVG_MATH_4_SCORE                 565\n",
       "AVG_MATH_8_SCORE                 602\n",
       "AVG_READING_4_SCORE              650\n",
       "AVG_READING_8_SCORE              562\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will print the number of valid values in each column\n",
    "df.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                     1715\n",
       "STATE                           1715\n",
       "YEAR                            1715\n",
       "ENROLL_ALL_EST                  1224\n",
       "TOTAL_REVENUE                   1275\n",
       "FEDERAL_REVENUE                 1275\n",
       "STATE_REVENUE                   1275\n",
       "LOCAL_REVENUE                   1275\n",
       "TOTAL_EXPENDITURE               1275\n",
       "INSTRUCTION_EXPENDITURE         1275\n",
       "SUPPORT_SERVICES_EXPENDITURE    1275\n",
       "OTHER_EXPENDITURE               1224\n",
       "CAPITAL_OUTLAY_EXPENDITURE      1275\n",
       "ENROLL_PREK                     1542\n",
       "ENROLL_KINDER                   1632\n",
       "ENROLL_4                        1632\n",
       "ENROLL_8                        1632\n",
       "ENROLL_12                       1632\n",
       "ENROLL_PRIMARY                  1020\n",
       "ENROLL_HS                       1071\n",
       "ENROLL_ALL                      1632\n",
       "AVG_MATH_4_SCORE                 565\n",
       "AVG_MATH_8_SCORE                 602\n",
       "AVG_READING_4_SCORE              650\n",
       "AVG_READING_8_SCORE              562\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice that pandas will often ignore missing values by default\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way we can deal with missing values is by dropping rows with any null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL_ALL_EST</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ENROLL_4</th>\n",
       "      <th>ENROLL_8</th>\n",
       "      <th>ENROLL_12</th>\n",
       "      <th>ENROLL_PRIMARY</th>\n",
       "      <th>ENROLL_HS</th>\n",
       "      <th>ENROLL_ALL</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>2003_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2003</td>\n",
       "      <td>727900.0</td>\n",
       "      <td>5196054.0</td>\n",
       "      <td>567704.0</td>\n",
       "      <td>2966981.0</td>\n",
       "      <td>1661369.0</td>\n",
       "      <td>5298932.0</td>\n",
       "      <td>2817111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57323.0</td>\n",
       "      <td>59663.0</td>\n",
       "      <td>42005.0</td>\n",
       "      <td>466920.0</td>\n",
       "      <td>205907.0</td>\n",
       "      <td>731220.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>2003_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>2003</td>\n",
       "      <td>133303.0</td>\n",
       "      <td>1425948.0</td>\n",
       "      <td>259423.0</td>\n",
       "      <td>813371.0</td>\n",
       "      <td>353154.0</td>\n",
       "      <td>1610289.0</td>\n",
       "      <td>763525.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10115.0</td>\n",
       "      <td>11140.0</td>\n",
       "      <td>8651.0</td>\n",
       "      <td>82337.0</td>\n",
       "      <td>40238.0</td>\n",
       "      <td>133933.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>2003_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>2003</td>\n",
       "      <td>875111.0</td>\n",
       "      <td>6529894.0</td>\n",
       "      <td>740579.0</td>\n",
       "      <td>2912629.0</td>\n",
       "      <td>2876686.0</td>\n",
       "      <td>6210287.0</td>\n",
       "      <td>2810907.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76207.0</td>\n",
       "      <td>76376.0</td>\n",
       "      <td>68815.0</td>\n",
       "      <td>613442.0</td>\n",
       "      <td>307272.0</td>\n",
       "      <td>1012068.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>2003_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>2003</td>\n",
       "      <td>450158.0</td>\n",
       "      <td>3241275.0</td>\n",
       "      <td>379947.0</td>\n",
       "      <td>2394336.0</td>\n",
       "      <td>466992.0</td>\n",
       "      <td>3242799.0</td>\n",
       "      <td>1768713.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34070.0</td>\n",
       "      <td>37004.0</td>\n",
       "      <td>28840.0</td>\n",
       "      <td>281834.0</td>\n",
       "      <td>132712.0</td>\n",
       "      <td>454523.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>2003_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>2003</td>\n",
       "      <td>6226552.0</td>\n",
       "      <td>59815855.0</td>\n",
       "      <td>5795655.0</td>\n",
       "      <td>33617766.0</td>\n",
       "      <td>20402434.0</td>\n",
       "      <td>59749885.0</td>\n",
       "      <td>29561563.0</td>\n",
       "      <td>...</td>\n",
       "      <td>493415.0</td>\n",
       "      <td>500143.0</td>\n",
       "      <td>395194.0</td>\n",
       "      <td>3929869.0</td>\n",
       "      <td>1854518.0</td>\n",
       "      <td>6413867.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>2015_VIRGINIA</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>2015</td>\n",
       "      <td>1279867.0</td>\n",
       "      <td>15857524.0</td>\n",
       "      <td>1012205.0</td>\n",
       "      <td>6240349.0</td>\n",
       "      <td>8604970.0</td>\n",
       "      <td>16113212.0</td>\n",
       "      <td>8755896.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96851.0</td>\n",
       "      <td>95221.0</td>\n",
       "      <td>90391.0</td>\n",
       "      <td>772414.0</td>\n",
       "      <td>386781.0</td>\n",
       "      <td>1283590.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>2015_WASHINGTON</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>2015</td>\n",
       "      <td>1072359.0</td>\n",
       "      <td>13709442.0</td>\n",
       "      <td>1036422.0</td>\n",
       "      <td>8293812.0</td>\n",
       "      <td>4379208.0</td>\n",
       "      <td>13630138.0</td>\n",
       "      <td>6508964.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82404.0</td>\n",
       "      <td>79483.0</td>\n",
       "      <td>89258.0</td>\n",
       "      <td>656797.0</td>\n",
       "      <td>336808.0</td>\n",
       "      <td>1087030.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>2015_WEST_VIRGINIA</td>\n",
       "      <td>WEST_VIRGINIA</td>\n",
       "      <td>2015</td>\n",
       "      <td>279565.0</td>\n",
       "      <td>3478401.0</td>\n",
       "      <td>362959.0</td>\n",
       "      <td>1979466.0</td>\n",
       "      <td>1135976.0</td>\n",
       "      <td>3466981.0</td>\n",
       "      <td>1819903.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19814.0</td>\n",
       "      <td>20426.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>162070.0</td>\n",
       "      <td>80142.0</td>\n",
       "      <td>277452.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>2015_WISCONSIN</td>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>2015</td>\n",
       "      <td>861813.0</td>\n",
       "      <td>11637376.0</td>\n",
       "      <td>814385.0</td>\n",
       "      <td>5869265.0</td>\n",
       "      <td>4953726.0</td>\n",
       "      <td>11553677.0</td>\n",
       "      <td>5723474.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60999.0</td>\n",
       "      <td>61084.0</td>\n",
       "      <td>66253.0</td>\n",
       "      <td>489919.0</td>\n",
       "      <td>263896.0</td>\n",
       "      <td>867800.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>2015_WYOMING</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>2015</td>\n",
       "      <td>93867.0</td>\n",
       "      <td>1962874.0</td>\n",
       "      <td>120290.0</td>\n",
       "      <td>1116917.0</td>\n",
       "      <td>725667.0</td>\n",
       "      <td>1942406.0</td>\n",
       "      <td>895910.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7551.0</td>\n",
       "      <td>6902.0</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>59453.0</td>\n",
       "      <td>26914.0</td>\n",
       "      <td>94717.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PRIMARY_KEY          STATE  YEAR  ENROLL_ALL_EST  TOTAL_REVENUE  \\\n",
       "561         2003_ALABAMA        ALABAMA  2003        727900.0      5196054.0   \n",
       "562          2003_ALASKA         ALASKA  2003        133303.0      1425948.0   \n",
       "563         2003_ARIZONA        ARIZONA  2003        875111.0      6529894.0   \n",
       "564        2003_ARKANSAS       ARKANSAS  2003        450158.0      3241275.0   \n",
       "565      2003_CALIFORNIA     CALIFORNIA  2003       6226552.0     59815855.0   \n",
       "...                  ...            ...   ...             ...            ...   \n",
       "1219       2015_VIRGINIA       VIRGINIA  2015       1279867.0     15857524.0   \n",
       "1220     2015_WASHINGTON     WASHINGTON  2015       1072359.0     13709442.0   \n",
       "1221  2015_WEST_VIRGINIA  WEST_VIRGINIA  2015        279565.0      3478401.0   \n",
       "1222      2015_WISCONSIN      WISCONSIN  2015        861813.0     11637376.0   \n",
       "1223        2015_WYOMING        WYOMING  2015         93867.0      1962874.0   \n",
       "\n",
       "      FEDERAL_REVENUE  STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  \\\n",
       "561          567704.0      2966981.0      1661369.0          5298932.0   \n",
       "562          259423.0       813371.0       353154.0          1610289.0   \n",
       "563          740579.0      2912629.0      2876686.0          6210287.0   \n",
       "564          379947.0      2394336.0       466992.0          3242799.0   \n",
       "565         5795655.0     33617766.0     20402434.0         59749885.0   \n",
       "...               ...            ...            ...                ...   \n",
       "1219        1012205.0      6240349.0      8604970.0         16113212.0   \n",
       "1220        1036422.0      8293812.0      4379208.0         13630138.0   \n",
       "1221         362959.0      1979466.0      1135976.0          3466981.0   \n",
       "1222         814385.0      5869265.0      4953726.0         11553677.0   \n",
       "1223         120290.0      1116917.0       725667.0          1942406.0   \n",
       "\n",
       "      INSTRUCTION_EXPENDITURE  ...  ENROLL_4  ENROLL_8  ENROLL_12  \\\n",
       "561                 2817111.0  ...   57323.0   59663.0    42005.0   \n",
       "562                  763525.0  ...   10115.0   11140.0     8651.0   \n",
       "563                 2810907.0  ...   76207.0   76376.0    68815.0   \n",
       "564                 1768713.0  ...   34070.0   37004.0    28840.0   \n",
       "565                29561563.0  ...  493415.0  500143.0   395194.0   \n",
       "...                       ...  ...       ...       ...        ...   \n",
       "1219                8755896.0  ...   96851.0   95221.0    90391.0   \n",
       "1220                6508964.0  ...   82404.0   79483.0    89258.0   \n",
       "1221                1819903.0  ...   19814.0   20426.0    18432.0   \n",
       "1222                5723474.0  ...   60999.0   61084.0    66253.0   \n",
       "1223                 895910.0  ...    7551.0    6902.0     6299.0   \n",
       "\n",
       "      ENROLL_PRIMARY  ENROLL_HS  ENROLL_ALL  AVG_MATH_4_SCORE  \\\n",
       "561         466920.0   205907.0    731220.0             223.0   \n",
       "562          82337.0    40238.0    133933.0             233.0   \n",
       "563         613442.0   307272.0   1012068.0             229.0   \n",
       "564         281834.0   132712.0    454523.0             229.0   \n",
       "565        3929869.0  1854518.0   6413867.0             227.0   \n",
       "...              ...        ...         ...               ...   \n",
       "1219        772414.0   386781.0   1283590.0             247.0   \n",
       "1220        656797.0   336808.0   1087030.0             245.0   \n",
       "1221        162070.0    80142.0    277452.0             235.0   \n",
       "1222        489919.0   263896.0    867800.0             243.0   \n",
       "1223         59453.0    26914.0     94717.0             247.0   \n",
       "\n",
       "      AVG_MATH_8_SCORE  AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n",
       "561              262.0                207.0                253.0  \n",
       "562              279.0                212.0                256.0  \n",
       "563              271.0                209.0                255.0  \n",
       "564              266.0                214.0                258.0  \n",
       "565              267.0                206.0                251.0  \n",
       "...                ...                  ...                  ...  \n",
       "1219             288.0                229.0                267.0  \n",
       "1220             287.0                226.0                267.0  \n",
       "1221             271.0                216.0                260.0  \n",
       "1222             289.0                223.0                270.0  \n",
       "1223             287.0                228.0                269.0  \n",
       "\n",
       "[355 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by default, dropna will remove all rows with at least 1 nan\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping rows with any nan leaves us only 355 rows -- do we actually need all our data to be complete? Which rows are actually important?\n",
    "\n",
    "That depends on what you want to do with the data! \n",
    "\n",
    "For the purpose of this tutorial, let's say we are particularly interested in 8th grade reading scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In that case, we will drop all the rows where the 8th grading reading score is missing\n",
    "df.dropna(subset=['AVG_READING_8_SCORE'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of dealing with missing values is filling them in with a value that is representative of other values in the column. Medians and means are common choices and are suited to different scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data, we have two columns representing total student enrollment: `ENROLL_ALL_EST` and `ENROLL_ALL`. We also have enrollment data divided by school group. Let's see if we can use them to fill each other in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(75)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ENROLL_ALL\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       433.000000\n",
       "mean       5375.538106\n",
       "std       18403.087434\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%        1524.000000\n",
       "max      156439.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first let's check if the individual enrollments actually sum up to total enrollment\n",
    "(df[\"ENROLL_ALL\"]-df[\"ENROLL_PREK\"]-df[\"ENROLL_KINDER\"]-df[\"ENROLL_PRIMARY\"]-df[\"ENROLL_HS\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    433.000000\n",
       "mean       0.463191\n",
       "std        1.143213\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.224393\n",
       "max        7.702014\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enrollment differences as a percent\n",
    "((df[\"ENROLL_ALL\"]-df[\"ENROLL_PREK\"]-df[\"ENROLL_KINDER\"]-df[\"ENROLL_PRIMARY\"]-df[\"ENROLL_HS\"])/df[\"ENROLL_ALL\"]*100).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the individual enrollments do sum up to the total enrollment in most cases! And even when they don't, the deviation is usually not drastic.\n",
    "\n",
    "This is not a terrible way to estimate total enrollment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ENROLL_ALL'] = df['ENROLL_ALL'].fillna(df[\"ENROLL_PREK\"]+df[\"ENROLL_PRIMARY\"]+df[\"ENROLL_HS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this didn't actually do anything!\n",
    "df[\"ENROLL_ALL\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns out, data missing ENROLL_ALL is also missing all other enrollment data\n",
    "df[df[\"ENROLL_ALL\"].isna()][['ENROLL_PREK','ENROLL_PRIMARY','ENROLL_HS','ENROLL_ALL_EST']].notna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but there are rows with enrollment estimates\n",
    "df[df.ENROLL_ALL_EST.isna()][\"ENROLL_ALL\"].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see if we can fill these in\n",
    "((df[\"ENROLL_ALL\"] - df[\"ENROLL_ALL_EST\"])/df[\"ENROLL_ALL\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the average error between estimated and actual enrollment is ~2%, I'm going to go ahead and fill in the missing estimates\n",
    "df[\"ENROLL_ALL_EST\"] = df[\"ENROLL_ALL_EST\"].fillna(df[\"ENROLL_ALL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we just did was data cleanup! Most data scientists will tell you that data cleanup and preprocessing will take >60% of the total time for a given project... We just gave you a small teaser here but you'll be seeing a lot more of it :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something else you'll see a lot of is feature engineering. In this step, we manipulate the data set so the data is can be used for analysis more readily.\n",
    "\n",
    "Here are some common methods of modifying features:\n",
    "\n",
    "* Standardization\n",
    ">helps some models account for different magnitude features, e.g. revenue is ~10x bigger than enrollment on average, but that doesn't make it more important\n",
    "* Binning\n",
    ">reduces the importance of small differences in data, e.g. exact enrollment probably doesn't matter, but there may still be a difference between 'small', 'medium', and 'large' schools\n",
    "* Combining features\n",
    ">combinations of features may matter more than the features on their own, e.g. educational expenditure as a percent of total expenditure is more informative about a state's priorities (states aren't all the same size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this case, we know our data is on the state level and also longitudinal (over time). \n",
    "\n",
    "This format introduces some complications. For example, the state of California will obviously spend more than New Jersey becuase they have more people... how can we account for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a new column which represents expenditure per student\n",
    "df['SUPPORT_SERVICES_EXPENDITURE_PER_STUDENT'] = df['SUPPORT_SERVICES_EXPENDITURE'] / df['ENROLL_ALL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do some EDA (exploratory data analysis)!\n",
    "\n",
    "You should always perform EDA when you are beginning to work with a new dataset. EDA will reveal irregularities and interesting patterns in the data, both of which are hugely informative for your work later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in EDA is usually looking at the variable of interest in isolation. What's its distribution? How has it changed over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note - this test is scored out of 500 according to the NAEP website\n",
    "df.AVG_READING_8_SCORE.plot.hist(title=\"Distribution of 8th Grade Reading Scores\", edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('YEAR')[\"AVG_READING_8_SCORE\"].mean().plot()\n",
    "plt.ylabel('SCORE')\n",
    "plt.title('8th Grade Reading Score Over Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can investigate the relationship between the variable of interest and other (potentially) relevant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='ENROLL_8', y='AVG_READING_8_SCORE', alpha=0.6)\n",
    "plt.xlabel('8th Grade Enrollment')\n",
    "plt.ylabel('8th Grade Reading Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='STATE_REVENUE', y='AVG_READING_8_SCORE', alpha=0.6)\n",
    "plt.xlabel('State Revenue')\n",
    "plt.ylabel('8th Grade Reading Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='INSTRUCTION_EXPENDITURE', y='AVG_READING_8_SCORE', alpha=0.6)\n",
    "plt.xlabel('Instruction Expenditure')\n",
    "plt.ylabel('8th Grade Reading Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='AVG_READING_4_SCORE', y='AVG_READING_8_SCORE', alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='AVG_MATH_8_SCORE', y='AVG_READING_8_SCORE', alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems 4th grade reading score and 8th grade math score are strongly correlated with 8th grade reading score. All the other variables that we investigated have weak or no correlation with 8th grade reading score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we know a bit about the data, what do we want to do with it? How am I going to frame this as a _machine learning_ project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Intro to Machine Learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we can't teach machine learning in single tutorial. For this tutorial, we're going to practice a simple _supervised learning_ problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine learning workflow:**\n",
    "<img src=https://miro.medium.com/proxy/1*KzmIUYPmxgEHhXX7SlbP4w.jpeg width=500></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised learning:**\n",
    "<img src=https://miro.medium.com/max/1050/1*-fniNC8gWI34qLAiBzgGZA.png width=800></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have established that we are interested in 8th grade reading scores, so I want to make that my response variable (i.e. what I'm trying to predict).\n",
    "\n",
    "Based on the EDA, I think that `ENROLL_8`, `AVG_MATH_8_SCORE`, and `AVG_READING_4_SCORE` would be interesting predictors to look at, so I will pick these as my input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_train_split randomly splits the data into two parts -- \n",
    "# one for training the model (it uses this data to learn patterns)\n",
    "# and one for testing the model (to make sure it performs well on data it hasn't seen before)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is commonly used to denote the input data\n",
    "# y is used for the response / output data\n",
    "X = df[['ENROLL_8','AVG_MATH_8_SCORE','AVG_READING_4_SCORE']].dropna()\n",
    "y = df.loc[X.index]['AVG_READING_8_SCORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need to make sure there is no NaN in y\n",
    "# This time, we will fill the NaN with the median of y \n",
    "# We prefer median to mean because EDA reveals that the response variable is left-skewed. Therefore, the mean may not represent the data very well\n",
    "y.fillna(y.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the test_size parameter defines what % of data is set aside for testing, 70 / 30 and 80 / 20 split are both typical\n",
    "# we don't have a huge data set but we still want to have a decently sized testing set\n",
    "# so we are using a 70 / 30 train / test split. \n",
    "# setting random_state explicitly ensures that I get the same results each time I run the code\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to create and train a model! For simplicity, I'm going to use `sklearn`'s `LinearRegression` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit is essentially the word sklearn uses for training\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are doing here is called _least squares linear regression_. \n",
    "\n",
    "Let's say there are $k$ input variables, named $x_1$ through $x_k$ (here, I have $k=3$, $x_1$ = `ENROLL_8`, $x_2$ = `AVG_MATH_8_SCORE`, etc.)\n",
    "\n",
    "The model is trying to find the one equation of the form that minimizes some error measure. In this case, that measure is residual sum of squares ([RSS](https://en.wikipedia.org/wiki/Residual_sum_of_squares)):\n",
    "\n",
    "$y_{predicted} = intercept + \\beta_0x_1 + \\beta_1x_2 + ... + \\beta_kx_k$ where $\\beta_i$ are the coefficients. \n",
    "\n",
    "Notice there are exactly $k$ coefficients. We can interpret each coefficient by holding all other variables constant (_ceteris paribus_, if you are feeling fancy). \n",
    "\n",
    "For example, if $\\beta_2=0.2$, we say \"with all other variables held constant, a 1 point increase in average grade 8 math score results in a 0.2-point increase in reading score\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see the intercepts and coefficients the model generates\n",
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 value describes how well a linear model fits the data\n",
    "# It ranges between 0 and 1\n",
    "# There are many caveats to R^2 but it is a good starting point\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean error\n",
    "np.mean(model.predict(X_test)-y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute error\n",
    "np.mean(np.abs(model.predict(X_test)-y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean squared error -- penalizes large errors\n",
    "np.mean((model.predict(X_test)-y_test)**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at the model's predictions and how it differs from the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'AVG_MATH_8_SCORE'\n",
    "\n",
    "f = plt.figure(figsize=(12,6))\n",
    "plt.scatter(X_train[col_name], y_train, color = \"red\")\n",
    "plt.scatter(X_train[col_name], model.predict(X_train), color = \"green\")\n",
    "\n",
    "plt.legend(['True Training','Predicted Training'])\n",
    "plt.xlabel(col_name)\n",
    "plt.ylabel('Reading 8 score')\n",
    "plt.title(\"Model Behavior On Training Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'AVG_MATH_8_SCORE'\n",
    "\n",
    "f = plt.figure(figsize=(12,6))\n",
    "plt.scatter(X_test[col_name], y_test, color = \"blue\")\n",
    "plt.scatter(X_test[col_name], model.predict(X_test), color = \"black\")\n",
    "\n",
    "plt.legend(['True testing','Predicted testing'])\n",
    "plt.xlabel(col_name)\n",
    "plt.ylabel('Reading 8 score')\n",
    "plt.title(\"Model Behavior on Testing Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would seem that our model works fairly well on the training set and also generalizes nicely to the testing set. This is a good thing! Sometimes models will work *too* well on the training set that it does poorly on the testing set. \n",
    "\n",
    "This is known as overfitting. We will have a lot more to say about it in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
